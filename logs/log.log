2018-09-29 09:51:32 INFO [CommonServer] - 准备开始启动通用服务...
2018-09-29 09:51:32 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 09:51:32 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 09:51:33 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 09:51:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 09:51:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 09:51:33 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 09:51:33 INFO [com.kds.kafka.Kafka] - 开始初始化Consumer...
2018-09-29 09:51:33 INFO [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = gp.java.common
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-29 09:51:33 INFO [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = gp.java.common
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-29 09:51:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 09:51:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 09:51:33 INFO [com.kds.kafka.Kafka] - Consumer完成初始化...
2018-09-29 09:51:33 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 09:51:33 INFO [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 192.168.100.70:9092 (id: 2147483647 rack: null) for group gp.java.common.
2018-09-29 09:51:33 INFO [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group gp.java.common
2018-09-29 09:51:33 INFO [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group gp.java.common
2018-09-29 09:51:34 INFO [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group gp.java.common with generation 1
2018-09-29 09:51:34 INFO [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [tp.test.common-0] for group gp.java.common
2018-09-29 09:51:45 INFO [ThreadServer] - 准备开始启动多线程测试服务...
2018-09-29 09:51:45 INFO [com.kds.kafka.Kafka] - 开始初始化Consumer...
2018-09-29 09:51:45 INFO [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = gp.java.common
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-29 09:51:45 INFO [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = gp.java.common
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-29 09:51:45 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 09:51:45 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 09:51:45 INFO [com.kds.kafka.Kafka] - Consumer完成初始化...
2018-09-29 09:51:45 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 09:51:45 INFO [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 192.168.100.70:9092 (id: 2147483647 rack: null) for group gp.java.common.
2018-09-29 09:51:45 INFO [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group gp.java.common
2018-09-29 09:51:45 INFO [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group gp.java.common
2018-09-29 09:51:46 INFO [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group gp.java.common with generation 3
2018-09-29 09:51:46 INFO [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [tp.test.common-0] for group gp.java.common
2018-09-29 09:52:35 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "55e418dec38a11e8bdf100005baedae2", "action": "common"}
2018-09-29 09:52:35 INFO [ThreadServer] - {"data": {"a": "1"}, "sessionid": "55e418dec38a11e8bdf100005baedae2", "action": "common"}
2018-09-29 09:52:46 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5c61a3cac38a11e8a05a00005baedaed", "action": "test"}
2018-09-29 09:52:46 INFO [ThreadServer] - {"data": {"a": "1"}, "sessionid": "5c61a3cac38a11e8a05a00005baedaed", "action": "test"}
2018-09-29 10:13:13 INFO [ThreadServer] - 准备开始启动多线程测试服务...
2018-09-29 10:13:13 INFO [com.kds.kafka.Kafka] - 开始初始化Consumer...
2018-09-29 10:13:13 INFO [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = gp.java.common
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-29 10:13:14 INFO [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = gp.java.common
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-09-29 10:13:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:14 INFO [com.kds.kafka.Kafka] - Consumer完成初始化...
2018-09-29 10:13:14 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:14 INFO [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 192.168.100.70:9092 (id: 2147483647 rack: null) for group gp.java.common.
2018-09-29 10:13:14 INFO [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group gp.java.common
2018-09-29 10:13:14 INFO [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group gp.java.common
2018-09-29 10:13:15 INFO [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group gp.java.common with generation 5
2018-09-29 10:13:15 INFO [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [tp.test.common-0] for group gp.java.common
2018-09-29 10:13:19 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "3bbbd7b8c38d11e88b2c00005baedfbf", "action": "test"}
2018-09-29 10:13:19 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:19 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:19 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:19 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:19 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:27 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "4029ca34c38d11e8a35700005baedfc6", "action": "test"}
2018-09-29 10:13:27 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:27 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:27 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:27 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:27 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:27 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:27 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:27 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:27 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "40ac6ac0c38d11e8b89e00005baedfc7", "action": "test"}
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:28 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:28 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:28 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:28 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:28 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "4111cea4c38d11e88b1a00005baedfc8", "action": "test"}
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:28 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:28 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-4
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:28 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:28 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:28 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "41357a4cc38d11e8afe900005baedfc8", "action": "test"}
2018-09-29 10:13:28 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:28 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:29 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-5
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:29 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:29 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:29 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "4171fc98c38d11e8b8e700005baedfc9", "action": "test"}
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:29 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:29 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-6
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:29 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:29 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:29 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "41909e06c38d11e88f8200005baedfc9", "action": "test"}
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:29 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:29 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-7
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:29 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:29 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:29 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "41af9aa8c38d11e8a22d00005baedfc9", "action": "test"}
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:29 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:29 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-8
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:29 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:29 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:29 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "41cdee88c38d11e899c200005baedfc9", "action": "test"}
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-9
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "41ece124c38d11e8994700005baedfc9", "action": "test"}
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-10
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "420e4770c38d11e884ee00005baedfca", "action": "test"}
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-11
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "42268b52c38d11e89a8b00005baedfca", "action": "test"}
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-12
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "42479f52c38d11e8910100005baedfca", "action": "test"}
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-13
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "4262e634c38d11e8a14100005baedfca", "action": "test"}
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-14
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:30 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:30 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "4280ddf8c38d11e8ae8900005baedfca", "action": "test"}
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-15
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:31 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:31 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "429e8f06c38d11e88cb100005baedfcb", "action": "test"}
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-16
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:31 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:31 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "42b9d510c38d11e8b3e300005baedfcb", "action": "test"}
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-17
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:31 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:31 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "42d5d7e6c38d11e8a2b500005baedfcb", "action": "test"}
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-18
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:31 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:31 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "42f0e2a8c38d11e887e100005baedfcb", "action": "test"}
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:31 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-19
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:31 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:31 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:31 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "430d42d2c38d11e891db00005baedfcb", "action": "test"}
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-20
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:32 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:32 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "432a139ec38d11e8876000005baedfcb", "action": "test"}
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-21
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:32 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:32 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "4346fe94c38d11e8b9c900005baedfcc", "action": "test"}
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-22
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:32 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:32 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "4362b6e8c38d11e8a64400005baedfcc", "action": "test"}
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-23
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:32 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:32 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "437ff002c38d11e88dd200005baedfcc", "action": "test"}
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:32 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-24
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:32 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:32 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:32 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "439d9ba4c38d11e887a400005baedfcc", "action": "test"}
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-25
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "43bd2276c38d11e8ade600005baedfcc", "action": "test"}
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-26
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "43d87f6ec38d11e8a49d00005baedfcd", "action": "test"}
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-27
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "43f4e502c38d11e8879400005baedfcd", "action": "test"}
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-28
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "4413e40cc38d11e8a23400005baedfcd", "action": "test"}
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:33 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-29
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:33 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:33 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "443477a2c38d11e88d3000005baedfcd", "action": "test"}
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-30
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:34 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:34 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "444f1f9ac38d11e8ad9100005baedfcd", "action": "test"}
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-31
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:34 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:34 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "446a4750c38d11e8b14e00005baedfce", "action": "test"}
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-32
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:34 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:34 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "448f0e36c38d11e8889f00005baedfce", "action": "test"}
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-33
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:34 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:34 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "44a8ebf6c38d11e89bed00005baedfce", "action": "test"}
2018-09-29 10:13:34 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:34 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-34
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:35 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:35 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:35 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "44c62a8ac38d11e8a64900005baedfce", "action": "test"}
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:35 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:35 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-35
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:35 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:35 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:35 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "44dd5a1cc38d11e88c6f00005baedfce", "action": "test"}
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:35 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:35 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-36
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:35 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:35 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:35 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:35 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:13:58 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "529b3b1ac38d11e8816a00005baedfe5", "action": "resp"}
2018-09-29 10:13:58 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:13:58 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:58 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-37
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:13:58 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:13:58 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:13:58 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:13:58 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:13:58 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:13:58 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "53fe731ec38d11e89d1500005baedfe8", "action": "resp"}
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:00 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:00 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-38
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:00 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:00 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:00 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "54209b2cc38d11e8ace500005baedfe8", "action": "resp"}
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:00 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:00 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-39
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:00 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:00 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:00 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5442272cc38d11e8874a00005baedfe8", "action": "resp"}
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:00 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:00 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-40
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:00 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:00 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:00 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "545f71a2c38d11e896c100005baedfe8", "action": "resp"}
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-41
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:01 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:01 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "547d1f86c38d11e8808700005baedfe9", "action": "resp"}
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-42
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:01 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:01 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "54988c6ec38d11e8b90a00005baedfe9", "action": "resp"}
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-43
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:01 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:01 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "54e17c50c38d11e89d1700005baedfe9", "action": "resp"}
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:01 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-44
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:01 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:01 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:01 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "54ebd7e2c38d11e895b400005baedfe9", "action": "resp"}
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-45
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:02 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:02 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "551f9ec0c38d11e8afe800005baedfea", "action": "resp"}
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-46
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:02 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:02 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "553f27d8c38d11e8b61200005baedfea", "action": "resp"}
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-47
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:02 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:02 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "555df7b0c38d11e8b38c00005baedfea", "action": "resp"}
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-48
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:02 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:02 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5576bc58c38d11e8986b00005baedfea", "action": "resp"}
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:02 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-49
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:02 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:02 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:02 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "55a844d4c38d11e8bcfa00005baedfea", "action": "resp"}
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-50
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:03 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:03 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "55c73dd2c38d11e8b7a500005baedfeb", "action": "resp"}
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-51
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:03 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:03 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "55e29b66c38d11e8932500005baedfeb", "action": "resp"}
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-52
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:03 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:03 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "55fe628ac38d11e8b6f700005baedfeb", "action": "resp"}
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:03 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-53
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:03 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:03 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:03 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5617be30c38d11e8917e00005baedfeb", "action": "resp"}
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-54
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:04 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:04 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "56370f80c38d11e8bae200005baedfeb", "action": "resp"}
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-55
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:04 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:04 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "56500e54c38d11e89eb600005baedfec", "action": "resp"}
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-56
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:04 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:04 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "566b95a8c38d11e8bb8400005baedfec", "action": "resp"}
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-57
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:04 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:04 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "56872126c38d11e8afa300005baedfec", "action": "resp"}
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:04 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-58
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:04 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:04 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:04 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "56a2361cc38d11e8804e00005baedfec", "action": "resp"}
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-59
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:05 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:05 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "56bcefc2c38d11e8a66c00005baedfec", "action": "resp"}
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-60
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:05 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:05 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "56d7c626c38d11e882e800005baedfec", "action": "resp"}
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-61
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:05 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:05 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "56f7e5d8c38d11e8ac8e00005baedfed", "action": "resp"}
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-62
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:05 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:05 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5712ffd0c38d11e894dd00005baedfed", "action": "resp"}
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:05 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-63
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:05 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:05 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:05 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "57379ae4c38d11e8a93b00005baedfed", "action": "resp"}
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-64
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5751ef68c38d11e8977500005baedfed", "action": "resp"}
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-65
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "577c51d4c38d11e8865b00005baedfee", "action": "resp"}
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-66
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5785b558c38d11e8ab1100005baedfee", "action": "resp"}
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-67
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "57a7b35cc38d11e8b94f00005baedfee", "action": "resp"}
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-68
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "57c62e02c38d11e8a44500005baedfee", "action": "resp"}
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-69
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:06 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:06 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:07 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:07 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "589aba3ec38d11e8b76a00005baedfef", "action": "resp"}
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-70
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:08 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:08 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "58b65f02c38d11e8a2f000005baedff0", "action": "resp"}
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-71
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:08 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:08 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "58d75522c38d11e8a85800005baedff0", "action": "resp"}
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-72
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:08 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:08 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "58f38f46c38d11e8b00a00005baedff0", "action": "resp"}
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-73
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:08 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:08 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:08 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:08 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "590ecf54c38d11e8a37a00005baedff0", "action": "resp"}
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-74
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "592b73dec38d11e89c4200005baedff0", "action": "resp"}
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-75
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "59439826c38d11e8958b00005baedff1", "action": "resp"}
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-76
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "595f26ccc38d11e883c000005baedff1", "action": "resp"}
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-77
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "599c8b74c38d11e88d2000005baedff1", "action": "resp"}
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-78
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "597c0c40c38d11e89bc700005baedff1", "action": "resp"}
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-79
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:09 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "59b4279ac38d11e882be00005baedff1", "action": "resp"}
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-80
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "59ceb486c38d11e8ab9f00005baedff1", "action": "resp"}
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-81
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "59eb7b1ec38d11e8bd1c00005baedff2", "action": "resp"}
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-82
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5a1fff42c38d11e898b100005baedff2", "action": "resp"}
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-83
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5a38bb98c38d11e89f0400005baedff2", "action": "resp"}
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-84
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:10 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5a549e46c38d11e8b92400005baedff2", "action": "resp"}
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-85
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5a70b040c38d11e8b7a000005baedff2", "action": "resp"}
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-86
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5a8cbe6cc38d11e88a4400005baedff3", "action": "resp"}
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-87
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "5aa4ee46c38d11e88a8400005baedff3", "action": "resp"}
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-88
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:14:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:14:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:14:11 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:14:11 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:49 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "950b737ec38d11e896bc00005baee055", "action": "resp"}
2018-09-29 10:15:49 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:49 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:49 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-89
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:49 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:49 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:49 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:49 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:49 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:49 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "9578222ec38d11e8881800005baee056", "action": "resp"}
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:50 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:50 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-90
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:50 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:50 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:50 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "95964d26c38d11e885b800005baee056", "action": "resp"}
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:50 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:50 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-91
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:50 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:50 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:50 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "95caef9cc38d11e8bd0f00005baee056", "action": "resp"}
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:50 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:50 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-92
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:50 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:50 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:50 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:50 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "95e9b880c38d11e8884000005baee056", "action": "resp"}
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-93
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:51 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:51 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "9605201cc38d11e8bac400005baee056", "action": "resp"}
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-94
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:51 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:51 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "96227b30c38d11e8848d00005baee057", "action": "resp"}
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-95
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:51 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:51 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "965ddebec38d11e8b6d400005baee057", "action": "resp"}
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-96
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:51 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:51 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "963bf37ac38d11e8a7a200005baee057", "action": "resp"}
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:51 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-97
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:51 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:51 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:51 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "9674da46c38d11e8b37500005baee057", "action": "resp"}
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-98
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:52 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:52 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "96d9cf2ec38d11e8861a00005baee058", "action": "resp"}
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-99
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:52 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:52 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "96fa7430c38d11e8a55700005baee058", "action": "resp"}
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-100
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:52 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:52 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "9715b32cc38d11e8afb600005baee058", "action": "resp"}
2018-09-29 10:15:52 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:52 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-101
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:53 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:53 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "97357f94c38d11e8992900005baee058", "action": "resp"}
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-102
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:53 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:53 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "9753f000c38d11e8862c00005baee059", "action": "resp"}
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-103
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:53 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:53 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "976dd662c38d11e897c500005baee059", "action": "resp"}
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-104
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:53 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:53 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "97842fa8c38d11e8abdb00005baee059", "action": "resp"}
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-105
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:53 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:53 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:53 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:53 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:54 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:54 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:15:54 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "97a178f6c38d11e898de00005baee059", "action": "resp"}
2018-09-29 10:15:54 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:15:54 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:54 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-106
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:15:54 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:15:54 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:15:54 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:15:54 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:15:54 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:15:54 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:08 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a08fe536c38d11e89db500005baee068", "action": "resp"}
2018-09-29 10:16:08 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:08 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:08 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-107
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:08 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:08 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:08 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:08 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a0a9c302c38d11e89c7100005baee068", "action": "resp"}
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-108
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a0c5265cc38d11e88b0f00005baee068", "action": "resp"}
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-109
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a0def71ec38d11e8951b00005baee069", "action": "resp"}
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-110
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a0f9abb4c38d11e8a63f00005baee069", "action": "resp"}
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-111
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a1123200c38d11e888cb00005baee069", "action": "resp"}
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:09 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-112
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:09 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:09 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a12c7590c38d11e89df900005baee069", "action": "resp"}
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-113
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a14739d2c38d11e8805200005baee069", "action": "resp"}
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-114
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a15d49d0c38d11e88ca300005baee069", "action": "resp"}
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-115
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a17b4d0cc38d11e8813700005baee06a", "action": "resp"}
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-116
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a195f318c38d11e8b2d900005baee06a", "action": "resp"}
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-117
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:10 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:10 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:10 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a1cbdbfac38d11e8bb6a00005baee06a", "action": "resp"}
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-118
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a1b2bdfec38d11e8b22600005baee06a", "action": "resp"}
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-119
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a1e100d8c38d11e8ad0200005baee06a", "action": "resp"}
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-120
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a1fb8042c38d11e89d1500005baee06b", "action": "resp"}
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-121
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a2301238c38d11e892d800005baee06b", "action": "resp"}
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-122
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a24e0692c38d11e8bc4100005baee06b", "action": "resp"}
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-123
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:11 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:11 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a267040cc38d11e89d5100005baee06b", "action": "resp"}
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-124
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:12 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:12 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a28488e4c38d11e8a7d400005baee06b", "action": "resp"}
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-125
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:12 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:12 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a2a41f92c38d11e8b73d00005baee06c", "action": "resp"}
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-126
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:12 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:12 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a2e617b4c38d11e8aad100005baee06c", "action": "resp"}
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-127
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:12 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:12 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:12 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:12 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a3040d64c38d11e8911100005baee06c", "action": "resp"}
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-128
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a31ba06ec38d11e89f4a00005baee06c", "action": "resp"}
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-129
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a333ef30c38d11e891d400005baee06d", "action": "resp"}
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-130
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a3503f70c38d11e8930100005baee06d", "action": "resp"}
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-131
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a36b605cc38d11e88e2a00005baee06d", "action": "resp"}
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-132
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a38bbc3ec38d11e882ad00005baee06d", "action": "resp"}
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-133
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:13 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:13 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a3b17b8ac38d11e8a62000005baee06d", "action": "resp"}
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-134
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a3bdeb3ec38d11e8b55a00005baee06d", "action": "resp"}
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-135
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a3db7154c38d11e8bdd400005baee06e", "action": "resp"}
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-136
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a3f78154c38d11e8b60800005baee06e", "action": "resp"}
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-137
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a40fcb9ec38d11e88b2800005baee06e", "action": "resp"}
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:14 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-138
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:14 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:14 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a42d8876c38d11e89f7f00005baee06e", "action": "resp"}
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-139
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a4451f0ac38d11e8bd8000005baee06e", "action": "resp"}
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-140
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a463a476c38d11e8b1fb00005baee06f", "action": "resp"}
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-141
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a47bd75cc38d11e88af700005baee06f", "action": "resp"}
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-142
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a494805ec38d11e88cb800005baee06f", "action": "resp"}
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-143
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a4ae5f58c38d11e8b23700005baee06f", "action": "resp"}
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-144
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:15 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:15 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:15 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a4c5fff6c38d11e8808300005baee06f", "action": "resp"}
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-145
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:16 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:16 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a4e58a94c38d11e891c100005baee06f", "action": "resp"}
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-146
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:16 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:16 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a4fc19f0c38d11e89b4a00005baee070", "action": "resp"}
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-147
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:16 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:16 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a523f9dcc38d11e8a64200005baee070", "action": "resp"}
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-148
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:16 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:16 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:16 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:16 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a532ac30c38d11e8942100005baee070", "action": "resp"}
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-149
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a56950fac38d11e8954600005baee070", "action": "resp"}
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-150
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a5850722c38d11e8b97a00005baee070", "action": "resp"}
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-151
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a5a504ecc38d11e8b6de00005baee071", "action": "resp"}
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-152
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a5bd9814c38d11e889b200005baee071", "action": "resp"}
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-153
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a5d4fab6c38d11e8a27100005baee071", "action": "resp"}
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-154
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:17 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:17 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:17 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a5f23ed4c38d11e8ab3600005baee071", "action": "resp"}
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-155
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a6088acac38d11e8afcd00005baee071", "action": "resp"}
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-156
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a62a3348c38d11e8990b00005baee072", "action": "resp"}
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-157
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a64079c6c38d11e88a2c00005baee072", "action": "resp"}
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-158
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a65721b4c38d11e8b71600005baee072", "action": "resp"}
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-159
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a6742eccc38d11e8859c00005baee072", "action": "resp"}
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-160
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:18 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:18 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:18 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a6951c90c38d11e89e0200005baee072", "action": "resp"}
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-161
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a6aa4a3ac38d11e89ff200005baee072", "action": "resp"}
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-162
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a6c59c5cc38d11e8b73a00005baee073", "action": "resp"}
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-163
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a6e285b0c38d11e8a8af00005baee073", "action": "resp"}
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-164
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a702a25ac38d11e88afa00005baee073", "action": "resp"}
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:19 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-165
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:19 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:19 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a71b7ebec38d11e8a76000005baee073", "action": "resp"}
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-166
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a7364938c38d11e8953700005baee073", "action": "resp"}
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-167
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a75200fec38d11e8b66e00005baee073", "action": "resp"}
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-168
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a76cb5f4c38d11e8b9e600005baee074", "action": "resp"}
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-169
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a78b393ac38d11e8b7d100005baee074", "action": "resp"}
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-170
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a7a177ccc38d11e891cb00005baee074", "action": "resp"}
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-171
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:20 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:20 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:20 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:21 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:21 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
2018-09-29 10:16:21 INFO [com.kds.kafka.Kafka] - 收到指令：{"data": {"a": "1"}, "sessionid": "a7bae9c2c38d11e8be0c00005baee074", "action": "resp"}
2018-09-29 10:16:21 INFO [com.kds.kafka.Kafka] - 开始初始化Producer...
2018-09-29 10:16:21 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:21 INFO [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = all
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.100.70:9092, 192.168.100.71:9092, 192.168.100.72:9092]
	buffer.memory = 33554432
	client.id = producer-172
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-09-29 10:16:21 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.10.1.0
2018-09-29 10:16:21 INFO [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : 3402a74efb23d1d4
2018-09-29 10:16:21 INFO [com.kds.kafka.Kafka] - Producer完成初始化...
2018-09-29 10:16:21 INFO [com.kds.kafka.Kafka] - **** START **** 启动了Kafka实例。
2018-09-29 10:16:21 INFO [org.apache.kafka.clients.producer.KafkaProducer] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-09-29 10:16:21 INFO [com.kds.kafka.Kafka] - **** STOP **** 停止了Kafka实例。
